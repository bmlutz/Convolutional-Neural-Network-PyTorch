{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"PyTorch CNN Image Classifier for CIFAR-10\n---\n---\n```\nStep 1: Examine Dataset\nStep 2: Split Dataset between Train and Val\nStep 3: Create Dataloaders and Move Data to GPU\nStep 4: Define Model\nStep 5: Set Hyperparameters\nStep 6: Train Model\n   -Generate Predictions\n   -Calculate Loss (Cross Entropy)\n   -Compute Gradient (Adam or SGD)\n   -Step\n   -Reset Gradient to Zero\nStep 7: Evaluate Model with Validation Set\nStep 8: Decide if Further Training is Necessary\nStep 9: Save Weights\n```","metadata":{}},{"cell_type":"code","source":"!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch \nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as tt\nimport torch.nn.functional as F\nimport tarfile\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nfrom torchvision.datasets import ImageFolder\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# check versions of torch and confirm detected device\nprint(torch.__version__)\nprint(torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2021-08-09T18:52:45.178345Z","iopub.execute_input":"2021-08-09T18:52:45.178733Z","iopub.status.idle":"2021-08-09T18:52:46.812156Z","shell.execute_reply.started":"2021-08-09T18:52:45.178653Z","shell.execute_reply":"2021-08-09T18:52:46.811058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# download the CIFAR-10 dataset\ndownload_url(\"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\", '.')\n\n# extract images and convert to tensors\nwith tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n    tar.extractall(path='./data')","metadata":{"execution":{"iopub.status.busy":"2021-08-09T18:52:55.332004Z","iopub.execute_input":"2021-08-09T18:52:55.332352Z","iopub.status.idle":"2021-08-09T18:53:19.941559Z","shell.execute_reply.started":"2021-08-09T18:52:55.332307Z","shell.execute_reply":"2021-08-09T18:53:19.940493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data augmentation to prevent overfitting\ntrain_transform = tt.Compose([tt.RandomCrop(32, padding=8, padding_mode='edge'), \n                         tt.RandomHorizontalFlip(),\n                         tt.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n                         tt.ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2021-08-09T18:53:35.6305Z","iopub.execute_input":"2021-08-09T18:53:35.630998Z","iopub.status.idle":"2021-08-09T18:53:35.63639Z","shell.execute_reply.started":"2021-08-09T18:53:35.630953Z","shell.execute_reply":"2021-08-09T18:53:35.635321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = ImageFolder('./data/cifar10/train', transform=train_transform)\ntest_ds = ImageFolder('./data/cifar10/test', transform=tt.ToTensor())","metadata":{"execution":{"iopub.status.busy":"2021-08-09T18:53:39.358042Z","iopub.execute_input":"2021-08-09T18:53:39.35845Z","iopub.status.idle":"2021-08-09T18:53:39.716966Z","shell.execute_reply.started":"2021-08-09T18:53:39.358421Z","shell.execute_reply":"2021-08-09T18:53:39.715918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set device to cpu or gpu depending on availability\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint('Device: ', device)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T18:53:42.886759Z","iopub.execute_input":"2021-08-09T18:53:42.887123Z","iopub.status.idle":"2021-08-09T18:53:42.895688Z","shell.execute_reply.started":"2021-08-09T18:53:42.887095Z","shell.execute_reply":"2021-08-09T18:53:42.894361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# examine dataset and print an image\nimg, label = train_ds[0]\nplt.imshow(img.permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2021-08-09T18:53:55.818225Z","iopub.execute_input":"2021-08-09T18:53:55.818578Z","iopub.status.idle":"2021-08-09T18:53:56.190411Z","shell.execute_reply.started":"2021-08-09T18:53:55.818534Z","shell.execute_reply":"2021-08-09T18:53:56.187982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nepochs = 10\nbatch_size = 128\nlearning_rate = 0.001\n#val_size = 5000\nworkers = 2\n\n'''\n# Splitting Dataset to create a Validation Set\ntorch.manual_seed(40)\ntrain_size = len(dataset) - val_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\n'''\n\n# DataLoader\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=workers, pin_memory=True)\ntest_dl = DataLoader(test_ds, batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n\n# Design Convolutional Neural Network model\nclass CnnModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n\n            nn.Flatten(), \n            nn.Linear(256*4*4, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10))\n\n    def forward(self, xb):\n        return self.network(xb)\n\n# Instantiate CNN\nmodel = CnnModel().to(device)\n# Instantiating Loss Function\ncriterion = nn.CrossEntropyLoss()\n# Instantiating Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T18:54:02.699855Z","iopub.execute_input":"2021-08-09T18:54:02.700217Z","iopub.status.idle":"2021-08-09T18:54:07.809776Z","shell.execute_reply.started":"2021-08-09T18:54:02.700187Z","shell.execute_reply":"2021-08-09T18:54:07.808726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntotal_step = len(train_dl)\nhistory = []\nfor epoch in range(epochs):\n    for i, (images, labels) in enumerate(train_dl):\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        ##FORWARD PASS##\n        # Make Prediction using CNN\n        yhat = model(images)\n        # Calculate Loss using Cross Entropy\n        loss = criterion(yhat, labels)\n        \n        ##BACKPROPAGATION##\n        # Calculate Gradient\n        loss.backward()\n        # Take Step\n        optimizer.step()\n        # Zero Gradients\n        optimizer.zero_grad()\n        \n        # Print Current State of Model\n        if (i+1) % 100 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n                   .format(epoch+1, epochs, i+1, total_step, loss.item()))\n    history.append(loss.item())","metadata":{"execution":{"iopub.status.busy":"2021-08-09T18:54:15.310813Z","iopub.execute_input":"2021-08-09T18:54:15.311254Z","iopub.status.idle":"2021-08-09T19:07:21.107387Z","shell.execute_reply.started":"2021-08-09T18:54:15.311223Z","shell.execute_reply":"2021-08-09T19:07:21.106132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the model\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_dl:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Test Accuracy of the model on test images: {} %'.format(100 * correct / total))\n\n# Save the model checkpoint\ntorch.save(model.state_dict(), 'model_ckpt.pth')","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:07:29.159058Z","iopub.execute_input":"2021-08-09T19:07:29.159448Z","iopub.status.idle":"2021-08-09T19:07:32.999341Z","shell.execute_reply.started":"2021-08-09T19:07:29.159398Z","shell.execute_reply":"2021-08-09T19:07:32.99805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the model loss as a function of epochs\nplt.plot(history, '-bx')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Training'])\nplt.title('Loss vs. No. of epochs');","metadata":{"execution":{"iopub.status.busy":"2021-08-09T19:08:33.91735Z","iopub.execute_input":"2021-08-09T19:08:33.917718Z","iopub.status.idle":"2021-08-09T19:08:34.129524Z","shell.execute_reply.started":"2021-08-09T19:08:33.917686Z","shell.execute_reply":"2021-08-09T19:08:34.12814Z"},"trusted":true},"execution_count":null,"outputs":[]}]}